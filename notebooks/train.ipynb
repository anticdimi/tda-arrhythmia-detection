{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import argparse\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Flatten, MaxPooling1D, PReLU\n",
    "from keras.initializers import Constant\n",
    "from keras.engine.input_layer import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1d_prelu(filters, kernel_size, alpha=0., bn=False, dropout=0.):\n",
    "    def layer(x):\n",
    "        x = Conv1D(filters=filters, kernel_size=kernel_size, padding='same')(x)\n",
    "        x = MaxPooling1D(pool_size=2)(x)\n",
    "        x = PReLU(alpha_initializer=Constant(value=alpha))(x)\n",
    "        if bn:\n",
    "            x = BatchNormalization()(x)\n",
    "        if dropout:\n",
    "            x = Dropout(rate=dropout)(x)\n",
    "        return x\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, kernel_sizes, filters, dropout_rate):\n",
    "    input = x = Input(shape=input_shape)\n",
    "\n",
    "    for kernel, filt in list(zip(kernel_sizes, filters)):\n",
    "        x = conv1d_prelu(filt, kernel, 0.25, True, dropout_rate)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(30)(x)\n",
    "    x = PReLU(alpha_initializer=Constant(value=0.25))(x)\n",
    "    z = Dense(2, activation='softmax')(x)\n",
    "\n",
    "    return Model(input, z, name='conv1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(train_x, train_y, test_x, test_y, dropout, epochs, batch_size, model_save):\n",
    "    model = build_model((train_x.shape[1], 1), [5, 5, 5, 3], [64, 128, 128, 128], dropout)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=1)\n",
    "    # evaluate model\n",
    "    loss, accuracy = model.evaluate(test_x, test_y, batch_size=batch_size, verbose=0)\n",
    "\n",
    "    model.save(model_save)\n",
    "    return history, accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/50\n761/761 [==============================] - 4s 5ms/step - loss: 1.2642 - accuracy: 0.6334\nEpoch 2/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.7295 - accuracy: 0.6873\nEpoch 3/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.6262 - accuracy: 0.7227\nEpoch 4/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5646 - accuracy: 0.7201\nEpoch 5/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.5483 - accuracy: 0.7385\nEpoch 6/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7346\nEpoch 7/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.5487 - accuracy: 0.7227\nEpoch 8/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5421 - accuracy: 0.7267\nEpoch 9/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.5442 - accuracy: 0.7319\nEpoch 10/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5356 - accuracy: 0.7411\nEpoch 11/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5285 - accuracy: 0.7267\nEpoch 12/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5285 - accuracy: 0.7411\nEpoch 13/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.5178 - accuracy: 0.7411\nEpoch 14/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5365 - accuracy: 0.7346\nEpoch 15/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.5113 - accuracy: 0.7424\nEpoch 16/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5287 - accuracy: 0.7372\nEpoch 17/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5233 - accuracy: 0.7411\nEpoch 18/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5196 - accuracy: 0.7503\nEpoch 19/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.5335 - accuracy: 0.7319\nEpoch 20/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5208 - accuracy: 0.7332\nEpoch 21/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5224 - accuracy: 0.7201\nEpoch 22/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5032 - accuracy: 0.7411\nEpoch 23/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.5154 - accuracy: 0.7438\nEpoch 24/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.5140 - accuracy: 0.7332\nEpoch 25/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4967 - accuracy: 0.7530\nEpoch 26/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.5114 - accuracy: 0.7346\nEpoch 27/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4866 - accuracy: 0.7582\nEpoch 28/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.4937 - accuracy: 0.7530\nEpoch 29/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.4847 - accuracy: 0.7635\nEpoch 30/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.4956 - accuracy: 0.7608\nEpoch 31/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4859 - accuracy: 0.7622\nEpoch 32/50\n761/761 [==============================] - 2s 3ms/step - loss: 0.4775 - accuracy: 0.7582\nEpoch 33/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4667 - accuracy: 0.7674\nEpoch 34/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4830 - accuracy: 0.7595\nEpoch 35/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4616 - accuracy: 0.7661\nEpoch 36/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4736 - accuracy: 0.7674\nEpoch 37/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4672 - accuracy: 0.7687\nEpoch 38/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4802 - accuracy: 0.7687\nEpoch 39/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4738 - accuracy: 0.7727\nEpoch 40/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4589 - accuracy: 0.7819\nEpoch 41/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4579 - accuracy: 0.7911\nEpoch 42/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4501 - accuracy: 0.7898\nEpoch 43/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4621 - accuracy: 0.7530\nEpoch 44/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4297 - accuracy: 0.7963\nEpoch 45/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4366 - accuracy: 0.8016\nEpoch 46/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4571 - accuracy: 0.7556\nEpoch 47/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4451 - accuracy: 0.7792\nEpoch 48/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4153 - accuracy: 0.7976\nEpoch 49/50\n761/761 [==============================] - 3s 4ms/step - loss: 0.4192 - accuracy: 0.8042\nEpoch 50/50\n761/761 [==============================] - 3s 3ms/step - loss: 0.4453 - accuracy: 0.7963\n"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/atthythmia_sliced_30.csv')\n",
    "X = df.iloc[:, :-1]\n",
    "y = df['class']\n",
    "y = to_categorical(y)\n",
    "\n",
    "X = np.expand_dims(X, axis=2)\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "train_history, test_accuracy, test_loss = evaluate_model(train_x, train_y, test_x, test_y, 0.5, 50, 32, '../models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_history(history):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train accuracy', 'train loss'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_1 (Conv1D)            (None, 200, 64)           384       \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 100, 64)           0         \n_________________________________________________________________\np_re_lu_1 (PReLU)            (None, 100, 64)           6400      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 100, 64)           0         \n_________________________________________________________________\nconv1d_2 (Conv1D)            (None, 100, 128)          41088     \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 50, 128)           0         \n_________________________________________________________________\np_re_lu_2 (PReLU)            (None, 50, 128)           6400      \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 50, 128)           0         \n_________________________________________________________________\nconv1d_3 (Conv1D)            (None, 50, 128)           82048     \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 25, 128)           0         \n_________________________________________________________________\np_re_lu_3 (PReLU)            (None, 25, 128)           3200      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 25, 128)           0         \n_________________________________________________________________\nconv1d_4 (Conv1D)            (None, 25, 128)           49280     \n_________________________________________________________________\nmax_pooling1d_4 (MaxPooling1 (None, 12, 128)           0         \n_________________________________________________________________\np_re_lu_4 (PReLU)            (None, 12, 128)           1536      \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 12, 128)           0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 1536)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 30)                46110     \n_________________________________________________________________\np_re_lu_5 (PReLU)            (None, 30)                30        \n_________________________________________________________________\ndense_2 (Dense)              (None, 2)                 62        \n=================================================================\nTotal params: 236,538\nTrainable params: 236,538\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('../models/model.h5')\n",
    "# summarize model.\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38264bittdaconda522e2e25bdc54781841ec8a5712db605",
   "display_name": "Python 3.8.2 64-bit ('tda': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}